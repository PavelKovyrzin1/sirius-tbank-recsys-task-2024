{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06d02967",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from tqdm.auto import tqdm\n",
    "import ast\n",
    "from catboost import CatBoostRegressor, Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "081ecd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./dataset_additional/\"\n",
    "\n",
    "users_df = pd.read_csv(data_folder + \"users_df.csv\")\n",
    "items_df = pd.read_csv(data_folder + \"items_df.csv\")\n",
    "\n",
    "countries = pd.read_csv(data_folder + \"countries.csv\")\n",
    "genres = pd.read_csv(data_folder + \"genres.csv\")\n",
    "staff = pd.read_csv(data_folder + \"staff.csv\")\n",
    "\n",
    "data_folder = \"./\"\n",
    "\n",
    "train_part = pd.read_csv(data_folder + \"train_data.csv\", parse_dates=[\"datetime\"])\n",
    "test_part = pd.read_csv(data_folder + \"test_data.csv\")\n",
    "test_part = test_part.groupby(\"user_id\").agg({\"movie_id\": list}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a691d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseRecommender(ABC):\n",
    "    def __init__(self):\n",
    "        self.trained = False\n",
    "\n",
    "    @abstractmethod\n",
    "    def fit(self, df: pd.DataFrame) -> None:\n",
    "        # реализация может быть любой, никаких ограничений\n",
    "\n",
    "        # не забудьте про\n",
    "        self.trained = True\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, df: pd.DataFrame, topn: int = 10) -> List[np.ndarray]:\n",
    "        # реализация может быть любой, НО\n",
    "        # должен возвращать список массивов из movie_id, которые есть в `item_df`, чтобы корректно работал подсчет метрик\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df661697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACHTUNG! DO NOT TOUCH \n",
    "\n",
    "def ndcg_metric(gt_items: np.ndarray, predicted: np.ndarray) -> float:\n",
    "    at = len(predicted)\n",
    "    relevance = np.array([1 if x in predicted else 0 for x in gt_items])\n",
    "    # DCG uses the relevance of the recommended items\n",
    "    rank_dcg = dcg(relevance)\n",
    "    if rank_dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    # IDCG has all relevances to 1 (or the values provided), up to the number of items in the test set that can fit in the list length\n",
    "    ideal_dcg = dcg(np.sort(relevance)[::-1][:at])\n",
    "\n",
    "    if ideal_dcg == 0.0:\n",
    "        return 0.0\n",
    "\n",
    "    ndcg_ = rank_dcg / ideal_dcg\n",
    "\n",
    "    return ndcg_\n",
    "\n",
    "\n",
    "def dcg(scores: np.ndarray) -> float:\n",
    "    return np.sum(\n",
    "        np.divide(np.power(2, scores) - 1, np.log2(np.arange(scores.shape[0], dtype=np.float64) + 2)), dtype=np.float64\n",
    "    )\n",
    "\n",
    "\n",
    "def recall_metric(gt_items: np.ndarray, predicted: np.ndarray) -> float:\n",
    "    n_gt = len(gt_items)\n",
    "    intersection = len(set(gt_items).intersection(set(predicted)))\n",
    "    return intersection / n_gt\n",
    "\n",
    "\n",
    "def evaluate_recommender(df: pd.DataFrame, model_preds_col: str, gt_col: str = \"movie_id\") -> Dict[str, float]:\n",
    "    metric_values = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        metric_values.append(\n",
    "            (ndcg_metric(row[gt_col], row[model_preds_col]), recall_metric(row[gt_col], row[model_preds_col]))\n",
    "        )\n",
    "\n",
    "    return {\"ndcg\": np.mean([x[0] for x in metric_values]), \"recall\": np.mean([x[1] for x in metric_values])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f91fa128",
   "metadata": {},
   "outputs": [],
   "source": [
    "items_df['genres'] = [ast.literal_eval(genres) for genres in items_df['genres']]\n",
    "items_df['countries'] = [ast.literal_eval(countries) for countries in items_df['countries']]\n",
    "items_df['staff'] = [ast.literal_eval(staff) for staff in items_df['staff']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e47062ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting(BaseRecommender):\n",
    "    def __init__(self, iterations: int = 1, learning_rate: float = 0.25, depth: int = 6):\n",
    "        super().__init__()\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.model = CatBoostRegressor(iterations=iterations, learning_rate=learning_rate, depth=depth, verbose=False)\n",
    "\n",
    "        \n",
    "        \n",
    "        # Бинарные признаки закодируем как 0 и 1, а остальные признаки являются порядковыми, \n",
    "        # поэтому можно их просто равномерно нормировать\n",
    "\n",
    "\n",
    "        self._age_encoder = {\n",
    "            '18-24': 0.0,\n",
    "            '25-34': 0.2,\n",
    "            '35-44': 0.45,\n",
    "            '45-54': 0.69,\n",
    "            '55-70': 1.0\n",
    "        }\n",
    "\n",
    "        self._income_encoder = {\n",
    "            'низкий': 0.0,\n",
    "            'средний': 0.33,\n",
    "            'высокий': 0.67,\n",
    "            'очень высокий': 1.0\n",
    "        }\n",
    "        \n",
    "        self._sex_encoder = {\n",
    "            'Женский': 0.0,\n",
    "            'Мужской': 1.0\n",
    "        }\n",
    "        \n",
    "        self._education_encoder = {\n",
    "            'Без образования': 0.0,\n",
    "            'Среднее': 0.33,\n",
    "            'Неполное высшее': 0.67,\n",
    "            'Высшее': 1.0\n",
    "        }\n",
    "        \n",
    "        \n",
    "    # Закодируем категориальные признаки в соответсвтии со словарями, None заменим средними значениями\n",
    "    def _prepare_categorical_features(self) -> None:\n",
    "        self.df['age_category'] = self.df['age_category'].replace(self._age_encoder)\n",
    "        self.df['age_category'].fillna(self.df['age_category'].mean(), inplace=True)\n",
    "\n",
    "        self.df['income'] = self.df['income'].replace(self._income_encoder)\n",
    "        self.df['income'].fillna(self.df['income'].mean(), inplace=True)\n",
    "        \n",
    "        self.df['sex'] = self.df['sex'].replace(self._sex_encoder)\n",
    "        self.df['sex'].fillna(self.df['sex'].mean(), inplace=True)\n",
    "        \n",
    "        self.df['education'] = self.df['education'].replace(self._education_encoder)\n",
    "        self.df['education'].fillna(self.df['education'].mean(), inplace=True)\n",
    "        \n",
    "        self.df['kids_flg'].fillna(self.df['kids_flg'].mean(), inplace=True)\n",
    "        \n",
    "    def _prepare_movies(self) -> None:\n",
    "        # Для каждого пользователя оставим только информацию о самых популярных фильмах\n",
    "        self.df['movie_id'] = [[movie for movie in movies if movie in self.recommendations] for movies in self.df['movie_id']]\n",
    "        \n",
    "        # Применим one-hot кодирование\n",
    "        binarized_column = self.mlb.fit_transform(self.df['movie_id'])\n",
    "        binarized_column_df = pd.DataFrame(binarized_column, columns=self.mlb.classes_)\n",
    "\n",
    "        self.df = pd.concat([self.df, pd.DataFrame(binarized_column_df)], axis=1)\n",
    "\n",
    "        self.df.drop(columns=['movie_id'], inplace=True)\n",
    "        \n",
    "        \n",
    "    def _prepare(self) -> None:\n",
    "        self._prepare_categorical_features()\n",
    "        self._prepare_movies()\n",
    "\n",
    "    def fit(self, train_df: pd.DataFrame, items_df: pd.DataFrame) -> None:\n",
    "        self.recommendations = set(train_df['movie_id'].value_counts().index.values[:100])\n",
    "        \n",
    "        self.df = train_df.groupby(\"user_id\").agg({\"movie_id\": list}).reset_index()\n",
    "        self.df = pd.merge(self.df, users_df, on='user_id', how='left')\n",
    "        \n",
    "        self.grouped_df = train_df.groupby(\"user_id\").agg({\"movie_id\": list}).reset_index()\n",
    "        \n",
    "        self.matrix = pd.DataFrame(self.mlb.fit_transform(self.df['movie_id']), columns=self.mlb.classes_)\n",
    "        \n",
    "        self._prepare()\n",
    "        self.trained = True\n",
    "        \n",
    "    def _predict(self, ind) -> None: # Функция предсказания для пользователей с номерами от ind до ind+test_rows\n",
    "        current_test_df = self.test_df.iloc[ind: min(ind + self.test_rows, len(self.test_df))]\n",
    "        \n",
    "        # Разделим данные на одучающую и тестовую части\n",
    "        mask = self.df['user_id'].isin(current_test_df['user_id'])\n",
    "        \n",
    "        train_indices = self.df.index[~mask]\n",
    "        test_indices = self.df.index[mask]\n",
    "\n",
    "        X_train = self.df.iloc[train_indices]\n",
    "        X_test = self.df.iloc[test_indices]\n",
    "        \n",
    "        for movie in self.matrix.columns: # Для каждого фильма обучим модель и сделаем предсказание\n",
    "            target_matrix = self.matrix[[movie]]\n",
    "            \n",
    "            y_train = target_matrix.iloc[train_indices]\n",
    "            \n",
    "            # Если ни один пользователь из обучающей части не посмотрел фильм, то обучать модель нет смысла\n",
    "            if len(y_train.iloc[:, 0].unique()) == 1: \n",
    "                self.ratings.loc[ind:min(ind + self.test_rows, len(self.test_df)), y_train.columns] = 0\n",
    "                continue\n",
    "                \n",
    "            # Если фильм популярный, то он присутствует как признак. \n",
    "            # В таком случае его нужно удалить, чтобы корректно обучить модель\n",
    "            if movie in self.recommendations:\n",
    "                train_pool = Pool(data=X_train.drop(columns=[movie]), label=y_train)\n",
    "                test_pool = Pool(data=X_test.drop(columns=[movie]))\n",
    "            else:\n",
    "                train_pool = Pool(data=X_train, label=y_train)\n",
    "                test_pool = Pool(data=X_test)                \n",
    "\n",
    "            self.model.fit(train_pool)\n",
    "\n",
    "            predictions = self.model.predict(test_pool)\n",
    "            \n",
    "            # Запишем предсказания в датафрейм ratings. Чем выше ratings[user_id][movie], \n",
    "            # тем вероятнее пользователь user_id посмотрит фильм movie\n",
    "            self.ratings.loc[ind:min(ind + self.test_rows, len(self.test_df)) - 1, y_train.columns] = predictions.reshape(-1, 1)\n",
    "\n",
    "    def predict(self, df: pd.DataFrame, test_parts: int = 1) -> list:\n",
    "        '''\n",
    "        test_parts в данном методе - это количество частей, на которые мы будем делить тестовую часть. \n",
    "        Т.е. если test_parts == len(test_part), то для каждого пользователя из тестовой части будем отдельно обучать \n",
    "        модель, используя для обучения всех пользователей кроме текущего. Если test_parts == 1, \n",
    "        то модель будем обучать только один раз - на всех пользователях кроме тестовых.\n",
    "        '''\n",
    "\n",
    "        assert self.trained\n",
    "\n",
    "        self.test_df = df\n",
    "        self.test_rows = len(df) // test_parts\n",
    "        \n",
    "        # Создаем матрицу, в которой для каждой пары (user_id, movie) будет записано предсказание.\n",
    "        self.ratings = pd.DataFrame(columns=self.matrix.columns, index=range(len(self.test_df)))\n",
    "        \n",
    "        # Делаем предсказания по частям\n",
    "        for ind in range (0, len(self.test_df), self.test_rows):\n",
    "            self._predict(ind)\n",
    "        \n",
    "        # Если пользователь user_id посмотрел фильм movie, то считаем, что ratings[user_id][movie] = 0,\n",
    "        # чтобы не рекомендовать фильм, который пользователь уже посмотрел.\n",
    "        for user in range(len(self.test_df)):\n",
    "            user_id = self.test_df.iloc[user]['user_id']\n",
    "            self.ratings.iloc[user][list(self.grouped_df[self.grouped_df['user_id'] == user_id]['movie_id'])[0]] = 0\n",
    "            \n",
    "        # Выбираем для каждого пользователя 10 фильмов с наивысшей оценкой.\n",
    "        self.ratings = self.ratings.astype(float)\n",
    "        top_10_movies = self.ratings.apply(lambda row: row.nlargest(10).index.tolist(), axis=1)\n",
    "\n",
    "        return top_10_movies.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b4a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GradientBoosting(iterations = 5, learning_rate = 0.25, depth = 6)\n",
    "model.fit(train_part, items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fe5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_part['gb_recs'] = model.predict(test_part, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83993fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_recommender(df=test_part, model_preds_col=\"gb_recs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
